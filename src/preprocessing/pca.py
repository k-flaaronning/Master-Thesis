# -*- coding: utf-8 -*-
"""PCA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D7ERyAySVMqh0f7fa9HzFkRTWSdSn285
"""

import tensorflow as tf
tf.test.gpu_device_name()

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnâ€™t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

# Code to read csv file into colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':'1nSAqJYO5thSWS0gFWDgmTTtsN7DJtQKD'}) # replace the id with id of file you want to access
downloaded.GetContentFile('Testing_Set1.csv')

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
df = pd.read_csv('Testing_Set1.csv', sep = ';') 
y_test = df['HP Flare']
df = df.drop('HP Flare', axis = 1)
df = df.interpolate(method = 'linear', axis = 0).ffill().bfill()
pca = PCA(n_components = 0.999)
projected = pca.fit_transform(df)

fig = plt.figure(figsize=(7,6))
ax = fig.add_subplot(111, projection = '3d')

axes = [-60000,60000]
ax.scatter(projected[:,0], projected[:,1], projected[:,2], cmap = plt.cm.hot)
ax.view_init(10, -70)
ax.set_xlabel('Dimension 1', fontsize = 10)
ax.set_ylabel('Dimension 2', fontsize = 10)
ax.set_zlabel('Dimension 1', fontsize = 10)

ax.set_xlim(axes[0:2])
ax.set_ylim(axes[0:2])
ax.set_zlim(axes[0:2])

plt.show()

pca = PCA().fit(df)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of components')
plt.ylabel('Cumulative explained variance');

pca = PCA()
pca.fit(df)
cumsum = np.cumsum(pca.explained_variance_ratio_)
d = np.argmax(cumsum >= 0.9999999) + 1

pca = PCA(n_components = 0.999999)
projected = pca.fit_transform(df)