# -*- coding: utf-8 -*-
"""CorrelationFeatureSlection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12FHar1ffoj79OrQ0tUqygHjBNnl4PAHS
"""

#------- Fix the usage of GPU -----------------------------------------------------

#' ' means CPU whereas '/device:G:0' means GPU
import tensorflow as tf
print(tf.test.gpu_device_name())

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnâ€™t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

#!kill -9 -1

from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':'1oF7toJFWt-tox50GM8I2AT_fvYITkgzZ'}) # replace the id with id of file you want to access
downloaded.GetContentFile('Data_namechanged.pkl')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.preprocessing import MinMaxScaler, StandardScaler

data = pd.read_pickle('Data_namechanged.pkl')
data_columns = data.columns
#data = data[data['HP Flare'] < data['HP Flare'].quantile(.90)]
data.describe()
scaler = MinMaxScaler()
data = pd.DataFrame(scaler.fit_transform(data), columns = data_columns)
target = data.pop('HP Flare')

desc = data.describe().T
desc['missing %'] = 1 - (desc['count'] /len(data))
desc = desc.sort_values(by='missing %', ascending = False)
plt.plot(np.arange(len(desc['missing %'])), desc['missing %'])
plt.xlabel('Number of Features')
plt.ylabel('Percentage of Missing Values')
data = data.interpolate(method='linear')
target = target.interpolate(method='linear')

#-------------Amount of variation -------------------------
#Drop variables with zero variation
var_data = data.var()
if False: # If True use the standard deviation. Use when not scaled
  var_data = np.sqrt(var_data) 

plt.plot(np.arange(len(var_data)), var_data.sort_values(ascending = False))
plt.xlabel('Number of Features')
plt.ylabel('Variance')

print('HP Flare variance: {}'.format(target.var()))

#Finds all features with variance lower than 1%
features_low_variance = var_data.loc[(var_data < 0.01)].index
print(features_low_variance[:])

#Find all feature correlations with target variable
target_corr = pd.concat([data, target], axis = 1, sort = False)
target_corr_matrix = target_corr.corr(method = 'spearman')
# If True, find the absolute correlation, If False find negative correlations as well
if True:
  target_corr_matrix = abs(target_corr_matrix.iloc[-1])
else:
  target_corr_matrix = target_corr_matrix.iloc[-1]
target_corr_matrix = target_corr_matrix.sort_values(ascending = False).iloc[1:]

plt.plot(np.arange(len(target_corr_matrix)), target_corr_matrix)
plt.xlabel('Number of Features')
plt.ylabel('Correlation with Target')
print(target_corr_matrix)

#Find selected feature correlations with target variable
selected_target_corr = pd.concat([data[features_low_variance], target], axis = 1, sort = False)
selected_target_corr_matrix = selected_target_corr.corr(method = 'spearman')
# If True, find the absolute correlation, If False find negative correlations as well
if True:
  selected_target_corr_matrix = abs(selected_target_corr_matrix.iloc[-1])
else:
  selected_target_corr_matrix = selected_target_corr_matrix.iloc[-1]
selected_target_corr_matrix = selected_target_corr_matrix.sort_values(ascending = False).iloc[1:]

plt.plot(np.arange(len(selected_target_corr_matrix)), selected_target_corr_matrix, c = 'red')
plt.xlabel('Number of Features')
plt.ylabel('Correlation with Target')

#Select features that has a correlation coefficient less than 0.01 with the target variable
features_low_variance_corr = selected_target_corr_matrix.loc[(selected_target_corr_matrix < 0.05)].index
print(selected_target_corr_matrix)

#---------- Pairwise Correlation -------------------------------------------

pc_data = data.copy()
print('Original dataset shape: {}'.format(pc_data.shape))
if True: # If True, drop columns with low variance
  pc_data = pc_data.drop(features_low_variance_corr, axis = 1)
print('Dataset shape after dropping features: {}'.format(pc_data.shape))
pc_data_index = pc_data.columns

#Calculates the correlation matrix
pc_corr_matrix = pc_data.corr(method = 'spearman')
pc_corr_matrix_target = abs(pd.concat([pc_data, target], axis = 1, sort = False).corr(method = 'spearman').iloc[-1])

temp = pc_corr_matrix_target
corrMatrix_final = pc_corr_matrix

#Method that finds features that are correlated above the threshold, then find the feature that are 
#most correlated with the target variable, delete the remaining features.
for col in corrMatrix_final:
    if col in corrMatrix_final.keys():
        thisCol = []
        thisVars = []
        for i in range(len(corrMatrix_final)):

            if abs(corrMatrix_final[col][i]) == 1.0 and col != corrMatrix_final.keys()[i]:
                thisCorr = 0
            else:
                thisCorr = (1 if abs(corrMatrix_final[col][i]) > 0.95 else -1) * abs(temp[[temp.keys()[i]]].values)
            thisCol.append(thisCorr)
            thisVars.append(corrMatrix_final.keys()[i])

        mask = np.ones(len(thisCol), dtype = bool)

        ctDelCol = 0

        for n, j in enumerate(thisCol):
            mask[n] =  (False if ((j[0] != max(thisCol)) & (j[0] >= 0)) else True)

            if ((j[0] != max(thisCol)) & (j[0] >= 0)):
                corrMatrix_final.pop('%s' %thisVars[n])
                temp.pop('%s' %thisVars[n])
                pc_data.pop('%s' %thisVars[n])
                ctDelCol += 1
        corrMatrix_final = corrMatrix_final[mask]

#Find the correlation with target variable for the remaining features
pc_data = pd.concat([pc_data, target],axis = 1, sort = False)
print('Dataset shape after pairwise: {}'.format(pc_data.shape))
pc_remain_corr_matrix = pc_data.corr(method = 'spearman')

if True:
  pc_remain_corr_matrix = abs(pc_remain_corr_matrix.iloc[-1])
else:
  pc_remain_corr_matrix = pc_remain_corr_matrix.iloc[-1]

pc_remain_corr_matrix = pc_remain_corr_matrix.sort_values(ascending = False).iloc[1:]
plt.plot(np.arange(len(pc_remain_corr_matrix)), pc_remain_corr_matrix)
plt.xlabel('Number of Features')
plt.ylabel('Correlation with Target')
print(pc_remain_corr_matrix.index)

#Remove all remaining features that have a correlation coefficient less than 0.05 with the target variable
final_corr_data = pc_remain_corr_matrix.loc[(pc_remain_corr_matrix > 0.05)].index
print(final_corr_data)
print(final_corr_data.shape)

